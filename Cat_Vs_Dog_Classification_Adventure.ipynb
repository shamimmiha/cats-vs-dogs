{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPXGgXcZsfJwwvPt0GHMKI3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdilShamim8/Cat_Vs_Dog_Image_Classification_Project/blob/main/Cat_Vs_Dog_Image_Classification_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üê± vs üê∂: The Ultimate Showdown - A Deep Learning Adventure\n",
        "\n",
        "## Starring: Adil and Harry - Two Friends on a Machine Learning Journey\n",
        "\n",
        "*Scene: It's a rainy Saturday afternoon. Adil and Harry are hanging out in their university dorm room, wondering what project to work on.*\n",
        "\n",
        "**Adil:** Hey Harry, you know what would be cool? If we could build something that can tell cats and dogs apart from photos!\n",
        "\n",
        "**Harry:** *(laughing)* Like you when you put on your glasses? Remember when you thought Mrs. Peterson's Chihuahua was a weird-looking cat?\n",
        "\n",
        "**Adil:** Very funny! But seriously, we could use that deep learning stuff Professor Johnson was talking about - Convolutional Neural Networks or something?\n",
        "\n",
        "**Harry:** CNNs! Yeah, that could actually be awesome. Let's do it! I've heard about this dataset on Kaggle with thousands of cat and dog images...\n",
        "\n",
        "**Adil:** Perfect! Let's fire up Google Colab and get started on our epic Cat vs Dog Classifier adventure!\n",
        "\n",
        "## Chapter 1: Getting Our Paws on Some Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Harry:** Alright, first things first. We need to get that dataset from Kaggle. Let's set up the Kaggle API so we can download it directly.\n",
        "\n",
        "**Adil:** Cool! We'll need to create a Kaggle account, get our API credentials, and then upload them here. I've already done that and have my `kaggle.json` file ready."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Set up the Kaggle API credentials\n",
        "# Note: You'll need to upload your kaggle.json file to Colab first!\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json  # Set proper permissions"
      ],
      "metadata": {
        "id": "Wep2D4sRLSot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Harry:** Hmm, looks like we need to upload our Kaggle API credentials first. If you're following along, you'll need to:\n",
        "\n",
        "1. Create a Kaggle account at kaggle.com\n",
        "2. Go to your account settings\n",
        "3. Scroll down to API section and click \"Create New API Token\"\n",
        "4. This will download a file called `kaggle.json`\n",
        "5. Upload this file to your Colab session using the files panel on the left\n",
        "\n",
        "**Adil:** And once we've done that, we can download the cats vs dogs dataset! Let's use the Kaggle command line tool."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Download the Cats vs Dogs dataset from Kaggle\n",
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ],
      "metadata": {
        "id": "K0HFD8yDMRjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adil:** Woohoo! The download is complete. Look at that - over 1GB of fluffy data! \n",
        "\n",
        "**Harry:** *(rubbing hands together)* Now we need to extract it. It's like opening a treasure chest full of digital cats and dogs!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Extract the dataset from the zip file\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/dogs-vs-cats.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()\n",
        "\n",
        "print(\"Dataset extraction complete! Let the cat and dog adventure begin!\")"
      ],
      "metadata": {
        "id": "xNJrQcxaMRp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 2: The Magic of Deep Learning - Setting Up Our Tools\n",
        "\n",
        "**Harry:** Alright, now that we have our data, we need to import all the deep learning libraries. It's like gathering our magical spells before the big battle!\n",
        "\n",
        "**Adil:** *(in a wizard voice)* I summon thee, oh mighty TensorFlow and the great Keras! Come forth and help us in our quest to distinguish between the feline and canine creatures!\n",
        "\n",
        "**Harry:** *(laughing)* You're such a nerd! But yes, let's import our libraries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Import the necessary libraries for our deep learning adventure\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(\"All magical deep learning libraries successfully summoned!\")"
      ],
      "metadata": {
        "id": "qlcJSF2QNi_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adil:** Great! Now we need to create what's called \"data generators\" for our training and validation data.\n",
        "\n",
        "**Harry:** What's a data generator?\n",
        "\n",
        "**Adil:** Think of it like a magical conveyor belt that feeds images into our model. Instead of loading all images at once (which would explode our computer's memory), it feeds them in small batches. Plus, it can automatically resize them all to the same dimensions.\n",
        "\n",
        "**Harry:** That's neat! Let's create these conveyor belts then."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Create data generators to efficiently load and preprocess our images\n",
        "# These are like magical conveyor belts feeding images to our model\n",
        "\n",
        "# Training data generator - for teaching our model\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/train',  # Folder containing training images\n",
        "    labels = 'inferred',           # Automatically figure out labels from folder names\n",
        "    label_mode = 'int',            # Represent labels as integers (0 for cats, 1 for dogs)\n",
        "    batch_size = 32,               # Process 32 images at a time\n",
        "    image_size = (256, 256)        # Resize all images to 256x256 pixels\n",
        ")\n",
        "\n",
        "# Validation data generator - for testing how well our model is learning\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/test',   # Folder containing validation images\n",
        "    labels = 'inferred',           # Automatically figure out labels from folder names\n",
        "    label_mode = 'int',            # Represent labels as integers (0 for cats, 1 for dogs)\n",
        "    batch_size = 32,               # Process 32 images at a time\n",
        "    image_size = (256, 256)        # Resize all images to 256x256 pixels\n",
        ")"
      ],
      "metadata": {
        "id": "t7KEV-C_OTuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Harry:** Wow! So we have 20,000 training images and 5,000 test images. That's a lot of cats and dogs!\n",
        "\n",
        "**Adil:** Yeah, but there's one more thing we need to do with our images. Right now, the pixel values are between 0 and 255, but neural networks work better with smaller numbers. So we'll divide all values by 255 to get them between 0 and 1. This is called \"normalization\".\n",
        "\n",
        "**Harry:** Like how we normalize test scores in school to be between 0 and 100?\n",
        "\n",
        "**Adil:** Exactly! It helps the model learn faster and better."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Normalize our image data from 0-255 to 0-1 range\n",
        "# Neural networks learn better with smaller numbers\n",
        "\n",
        "def process(image, label):\n",
        "    # Convert from 0-255 range to 0-1 range by dividing by 255\n",
        "    image = tf.cast(image/255., tf.float32)\n",
        "    return image, label\n",
        "\n",
        "# Apply our normalization function to both datasets\n",
        "train_ds = train_ds.map(process)\n",
        "validation_ds = validation_ds.map(process)\n",
        "\n",
        "print(\"Image normalization complete! All pixel values now between 0 and 1.\")"
      ],
      "metadata": {
        "id": "fklSUYWQOTyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 3: Building Our Cat vs Dog Detective - The CNN Model\n",
        "\n",
        "**Adil:** Now comes the exciting part - building our Convolutional Neural Network (CNN)!\n",
        "\n",
        "**Harry:** What exactly is a CNN again? I remember it has something to do with filters?\n",
        "\n",
        "**Adil:** Exactly! Think of CNNs like this: Imagine you're looking at a photo through a series of special glasses. The first pair helps you see edges and simple shapes, the next pair helps you see more complex patterns, and so on. Each layer of our CNN is like a different pair of these special glasses, helping the model understand the image at different levels of complexity.\n",
        "\n",
        "**Harry:** That makes sense! And I guess the last part of the model makes the final decision - \"Is this a cat or a dog?\"\n",
        "\n",
        "**Adil:** Exactly! Let's build it step by step:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Create our Convolutional Neural Network (CNN) model\n",
        "# This is like building a brain that can learn to recognize cats and dogs!\n",
        "\n",
        "model = Sequential()  # Sequential means we're stacking layers one after another\n",
        "\n",
        "# === FIRST CONVOLUTIONAL BLOCK ===\n",
        "# Convolution layer - learns to detect simple features like edges\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), padding='valid', activation='relu', input_shape=(256, 256, 3)))\n",
        "# Batch Normalization - helps the model train faster and more stably\n",
        "model.add(BatchNormalization())\n",
        "# Max Pooling - reduces the image size while keeping important features\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "# === SECOND CONVOLUTIONAL BLOCK ===\n",
        "# More filters (64) to detect more complex patterns\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding='valid', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "# === THIRD CONVOLUTIONAL BLOCK ===\n",
        "# Even more filters (128) for even more complex features\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), padding='valid', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "# === FLATTEN AND DENSE LAYERS ===\n",
        "# Flatten - converts the 2D feature maps to a 1D feature vector\n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense layers - learn to combine features to make the final decision\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.1))  # Dropout - prevents overfitting by randomly turning off 10% of neurons\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "# Final output layer - one neuron with sigmoid activation for binary classification\n",
        "# (0 = cat, 1 = dog)\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(\"Neural network architecture successfully constructed!\")"
      ],
      "metadata": {
        "id": "etUnJrJEOT1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Harry:** Whoa, that's a lot of layers! Can we see a summary of the model to understand its structure better?\n",
        "\n",
        "**Adil:** Great idea! Let's call the `summary()` method to see how many parameters (or \"weights\") our model has and how the data changes shape as it flows through the network."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Display a summary of our model architecture\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "9QJxqHU3OT5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Harry:** *(whistles)* 14.8 million parameters! That's a lot for our model to learn.\n",
        "\n",
        "**Adil:** Yes, but that's what makes deep learning powerful! Each of those parameters will be adjusted during training to get better at the task. Now, we need to \"compile\" our model, which means setting up how it will learn.\n",
        "\n",
        "**Harry:** Like choosing the learning strategy?\n",
        "\n",
        "**Adil:** Exactly! We need to specify:\n",
        "1. An optimizer - this determines how to adjust the weights (we'll use Adam, which is like a smart teacher)\n",
        "2. A loss function - this measures how wrong our predictions are (binary_crossentropy is good for yes/no problems like ours)\n",
        "3. Metrics - these help us monitor how well we're doing (accuracy is easy to understand)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Compile our model - set up the learning process\n",
        "model.compile(\n",
        "    optimizer='adam',               # Adam optimizer - a smart algorithm to adjust weights\n",
        "    loss='binary_crossentropy',     # Loss function for binary (two-class) problems\n",
        "    metrics=['accuracy']            # We want to track accuracy during training\n",
        ")\n",
        "\n",
        "print(\"Model compiled and ready for training!\")"
      ],
      "metadata": {
        "id": "cHxFLUnHOT82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 4: Training Our Model - The Learning Process\n",
        "\n",
        "**Harry:** So now our model is ready to learn. How do we actually train it?\n",
        "\n",
        "**Adil:** We use the `fit` method, which repeatedly shows our model the training images, lets it make predictions, and then adjusts its weights based on how wrong it was. Over time, it gets better and better!\n",
        "\n",
        "**Harry:** Like how we learn from our mistakes?\n",
        "\n",
        "**Adil:** Exactly! And we'll train for 10 epochs, which means we'll go through the entire training dataset 10 times. Let's watch it learn!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Train our model on the cat and dog images\n",
        "history = model.fit(\n",
        "    train_ds,                  # Our training data\n",
        "    epochs=10,                 # Number of times to go through the entire dataset\n",
        "    validation_data=validation_ds  # Data to evaluate progress after each epoch\n",
        ")"
      ],
      "metadata": {
        "id": "-Y3PqlHlYDpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Harry:** Wow! Look at that progress! We started at around 57% accuracy in the first epoch and ended up at over 97% by the end. Our model learned to tell cats and dogs apart with amazing accuracy!\n",
        "\n",
        "**Adil:** Indeed! But let's visualize the learning process to better understand what happened during training. We'll plot the accuracy and loss curves."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Visualize the training and validation accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['accuracy'], color='red', label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], color='blue', label='Validation Accuracy')\n",
        "plt.title('Model Accuracy Over Time', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n_8WmotwYDro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adil:** This graph shows how our model's accuracy improved with each epoch (training cycle). The red line is the accuracy on the training data, and the blue line is the accuracy on the validation data (images the model hasn't seen during training).\n",
        "\n",
        "**Harry:** I notice that the training accuracy (red line) is higher than the validation accuracy (blue line), especially toward the end. Is that normal?\n",
        "\n",
        "**Adil:** Good observation! That's a sign of something called \"overfitting\" - where the model starts to memorize the training data rather than learning general patterns. It's like if you memorized all the answers to a practice test but then struggled with slightly different questions on the real exam.\n",
        "\n",
        "**Harry:** Let's also look at the loss curves to see if they show the same pattern."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Visualize the training and validation loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], color='red', label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], color='blue', label='Validation Loss')\n",
        "plt.title('Model Loss Over Time', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=14)\n",
        "plt.xlabel('Epoch', fontsize=14)\n",
        "plt.legend(fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "74oEJgXTanQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Harry:** Yes, I can see the same pattern in the loss curves - the training loss (red) keeps decreasing, but the validation loss (blue) starts to level off and might even increase a bit. What can we do about this overfitting issue?\n",
        "\n",
        "**Adil:** There are several techniques to combat overfitting. Let's list some of them:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 13: Ways to reduce overfitting in deep learning models\n",
        "\n",
        "print(\"Ways to Reduce Overfitting in Deep Learning Models:\")\n",
        "print(\"1. Add more training data - More examples help the model generalize better\")\n",
        "print(\"2. Data Augmentation - Create variations of existing images by flipping, rotating, etc.\")\n",
        "print(\"3. L1/L2 Regularization - Add penalties for large weights to the loss function\")\n",
        "print(\"4. Dropout - Randomly turn off neurons during training (we already used this!)\")\n",
        "print(\"5. Batch Normalization - Normalize layer inputs (we already used this too!)\")\n",
        "print(\"6. Reduce model complexity - Use a simpler model with fewer parameters\")\n",
        "print(\"7. Early stopping - Stop training when validation metrics start to degrade\")"
      ],
      "metadata": {
        "id": "wcwW7n0janTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chapter 5: Testing Our Model - The Moment of Truth\n",
        "\n",
        "**Harry:** Enough theory! Let's test our model on a new image and see if it can correctly identify a cat or a dog!\n",
        "\n",
        "**Adil:** Great idea! First, we need to import OpenCV to load and process the image."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 14: Import OpenCV for image processing\n",
        "import cv2"
      ],
      "metadata": {
        "id": "Oe6-cI_7anWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Harry:** For this test, I've uploaded a picture of my dog, Max. Let's see if the model can recognize him as a dog!\n",
        "\n",
        "**Adil:** Let's load the image first. Make sure you've uploaded a file named 'dog.jpg' to Colab using the file upload button on the left sidebar."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 15: Load and preprocess a test image\n",
        "test_img = cv2.imread('/content/dog.jpg')\n",
        "\n",
        "# Check if the image loaded correctly\n",
        "if test_img is None:\n",
        "    print(\"Error loading image! Make sure you've uploaded 'dog.jpg' to Colab.\")\n",
        "else:\n",
        "    print(\"Image loaded successfully!\")"
      ],
      "metadata": {
        "id": "kPohUunlanYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adil:** Now let's display the image to make sure it looks correct."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 16: Display the test image\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for correct colors\n",
        "plt.title(\"Our Test Image\", fontsize=16)\n",
        "plt.axis('off')  # Hide the axes\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8rx5g8esfUrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Harry:** That's Max alright! But our model expects images to be 256x256 pixels, and this image is probably a different size. Let's check."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 17: Check the original image dimensions\n",
        "print(f\"Original image shape: {test_img.shape} (height, width, channels)\")"
      ],
      "metadata": {
        "id": "PslDoxBcfaGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adil:** As expected, we need to resize it to 256x256 pixels to match what our model expects."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 18: Resize the image to 256x256 pixels to match our model's input requirements\n",
        "test_img = cv2.resize(test_img, (256, 256))\n",
        "print(f\"Resized image shape: {test_img.shape} (height, width, channels)\")"
      ],
      "metadata": {
        "id": "3rh17N-yfaLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Harry:** Now we need to reshape it to match what our model expects. Models want batches of images, even if we only have one image."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 19: Reshape the image to have a batch dimension (batch size of 1)\n",
        "test_input = test_img.reshape((1, 256, 256, 3))\n",
        "\n",
        "# Don't forget to normalize the pixel values to [0,1] range, just like we did during training!\n",
        "test_input = test_input / 255.0\n",
        "\n",
        "print(f\"Final input shape: {test_input.shape} (batch_size, height, width, channels)\")"
      ],
      "metadata": {
        "id": "sdr7lbhmfxZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adil:** Now for the moment of truth! Let's ask our model whether this is a cat or a dog. Remember, our model outputs a number between 0 and 1, where:\n",
        "- Values close to 0 mean the model thinks it's a cat\n",
        "- Values close to 1 mean the model thinks it's a dog"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 20: Make a prediction with our model\n",
        "prediction = model.predict(test_input)\n",
        "\n",
        "# Convert the raw prediction to a user-friendly result\n",
        "probability = prediction[0][0]  # Get the probability value\n",
        "result = \"DOG üê∂\" if probability > 0.5 else \"CAT üò∫\"\n",
        "\n",
        "print(f\"\\nThe model is {probability * 100:.2f}% confident that this is a {result}!\")\n",
        "\n",
        "# Display the image with the prediction\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB))\n",
        "plt.title(f\"Prediction: {result} ({probability * 100:.2f}% confident)\", fontsize=16)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "apGP7V3-fxcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epilogue: The Journey Continues\n",
        "\n",
        "**Harry:** Amazing! Our model correctly identified Max as a dog! This is incredible.\n",
        "\n",
        "**Adil:** I know, right? We just taught a computer to tell the difference between cats and dogs with over 97% accuracy. That's the power of deep learning!\n",
        "\n",
        "**Harry:** What else could we do with this model?\n",
        "\n",
        "**Adil:** So many things! We could:\n",
        "1. Try transfer learning using pre-trained models like VGG16 or ResNet to get even better accuracy\n",
        "2. Expand it to recognize more animal species\n",
        "3. Build a web app or mobile app where users can upload photos and get predictions\n",
        "4. Implement real-time pet detection with a webcam\n",
        "\n",
        "**Harry:** *(excitedly)* Let's do all of that! But first, I'm going to show this to my mom. She always mixes up photos of my friend's cat and dog!\n",
        "\n",
        "**Adil:** *(laughing)* Perfect use case! And next time, let's try to make a model that can tell apart different dog breeds. I bet my Labrador from your Poodle!\n",
        "\n",
        "**Harry:** You're on! Deep learning adventure continues!\n",
        "\n",
        "## üéâ The End... or just the beginning of your deep learning journey! üéâ\n",
        "\n",
        "### Next Steps for the Curious Learner:\n",
        "1. Try the model on more images\n",
        "2. Implement data augmentation to reduce overfitting\n",
        "3. Experiment with different model architectures\n",
        "4. Learn about transfer learning to boost accuracy with fewer training examples\n",
        "5. Deploy your model in a web application\n",
        "\n",
        "Happy coding! üê±üê∂"
      ]
    }
  ]
}